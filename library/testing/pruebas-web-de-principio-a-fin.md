# üåê E2E Pruebas externas de principio a fin

Pruebas de aplicaciones web de caja negra. Puppeteer para comprobaci√≥n de existencia, navegaci√≥n, tama√±o, velocidad y otras m√©tricas.

> _"Si un usuario final percibe una mal rendimiento en tu website, su siguiente click probablemente sea en tu-competencia.com"_
>
> -- ‚úçÔ∏è **Ian Molyneaux**

Lo primero es **software que funcione**. Y cuando hablamos de una _web_ la primera garant√≠a debe ser la existencia y la descarga r√°pida de contenido relevante.

Todo lo dem√°s vendr√° despu√©s. Paro si el usuario no encuentra r√°pido lo que busca... entonces si puede se ir√°, y si no puede irse estar√° a disgusto. Ninguna de las dos situaciones es deseable.

Pero, afortunadamente, es muy sencillo realizar unos primeros test que garanticen estos aspectos tan b√°sicos de nuestros sistemas.

La herramienta que os propongo utilizar es [Puppeteer](https://pptr.dev/). Aunque todo se puede realizar con otras como [Cypress](https://www.cypress.io/) o [Playwright](https://github.com/microsoft/playwright). La primera la usaremos para pruebas m√°s funcionales, y la segunda es muy reciente y habr√° que darle algo de tiempo...

Lo interesante no es el software que usemos, sino **tener claro cual es el objetivo de la prueba**. Que en este caso es tremendamente simple.

- ‚úÖ Garantizar que una ruta existe.

- ‚úÖ Comprobar que el contenido es el esperado.

- ‚úÖ Validar que sus m√©tricas entran en un rango esperado.

Son casi [pruebas de humo](https://es.wikipedia.org/wiki/Pruebas_de_humo) para comprobar que algo no arde nada m√°s enchufarlo. Pero por **su simplicidad para implantarlas y su coste tan asequible de ejecuci√≥n** son la primera recomendaci√≥n que puedo dar a un _web tester_.


Vamos a usar _Puppeteer_ para realizar una pruebas muy b√°sicas. Pero vamos a **prepararlo y automatizarlo** de forma que sea muy sencillo y barato realizarlas con frecuencia.

Para seguir este tutorial no se requiere ning√∫n conocimiento previo sobre testing. Pero se recomienda familiarizarse con la terminolog√≠a leyendo el art√≠culo [Filosof√≠a y patrones](https://www.bitademy.com/tutorial/web-testing/filosofia-y-patrones)

<div class="page"/>

## Puppeteer

Lo primero es tener las herramientas adecuadas. Instalamos Puppeteer con el comando `yarn add puppeteer`. Y empezamos a programar.
Os propongo desarrollar un script Node que tome como dependencia a [Puppeteer](https://pptr.dev/),  lo lance y lo cierre.

```javascript
const { getBrowser, closeBrowser, takeScreenshot } = require(`./lib/puppets`);
async function test() {
  const { browser, pagePuppet } = await arrangeBefore();
  await cleanAfter(browser);
}
async function arrangeBefore() {
  const browser = await getBrowser();
  const pagePuppet = await browser.newPage();
  return { browser, pagePuppet };
}
async function cleanAfter(browser) {
  await closeBrowser(browser);
}
```

Veamos en detalle:

### El browser

La secci√≥n de preparaci√≥n de cualquier test debe dejarlo listo para la ejecuci√≥n de pruebas. Habitualmente **se preparan objetos** de negocio, ficheros, servicios o como en este caso se configura _Puppeteer_ para visitar p√°ginas en modo oculto y a la resoluci√≥n que determinemos.

```javascript
exports.getBrowser = async function getBrowser() {
  if (!browser) {
    browser = await puppeteer.launch({
      headless: false,
      defaultViewport: { width: 1920, height: 1080 },
      devtools: false
    });
  }
  return browser;
};
```

Y ahora aun par de pruebas.

### La p√°gina

A partir de este momento ya empezamos con **lo que deber√≠a ocurrir**. Y lo m√°s sencillo es determinar que una p√°gina existe y devuelve un c√≥digo http v√°lido. Acost√∫mbrate a la sintaxis as√≠ncrona con `async-await` porque todo esto se ejecutar√° siempre en segundo plano.

```javascript
module.exports = async function (pagePuppet) {
  const inputPageUrl = `https://www.bitademy.com/`;
  await given(`A the url ${inputPageUrl}`, async () => {
    await when(`we visit it`, async () => {
      const response = await pagePuppet.goto(inputPageUrl, { waitUntil: `load` });
      let actual = response.ok();
      let expected = true;
      then(`respond with an ok status code`, actual, expected);
    });
  });
};
```

F√≠jate en la auditoria tan expl√≠cita que se hace. En un test siempre querr√°s saber lo que est√° pasando. Recuerda que es una herramienta para el desarrollador, es decir, para ti. As√≠ que haz que te resulte c√≥moda, agradable y util.

Para homogenizar los mensajes te propongo que uses la terminolog√≠a que tomo prestada del BDD. Se basa en usar los tres sucesos de toda prueba. _Given, when, then_. Es decir **dada** una situaci√≥n de partida, **cuando** el usuario realiza una acci√≥n, **entonces** el sistema deber√≠a responder adecuadamente.

### El contenido

Este caso de comprobar **existencia** es habitual, aunque mucho m√°s habitual ser√° comprobar **contenido**. Por ejemplo si la p√°gina existe pero queremos comprobar que es la adecuada. Para ello se usan m√©todos auxiliares para obtener acceso a la respuesta.

```javascript
module.exports = async function (pagePuppet) {
  const inputPageUrl = `https://www.bitademy.com/`;
  await given(`A the page at ${inputPageUrl}`, async () => {
    await when(`we get its title`, async () => {
      await pagePuppet.goto(inputPageUrl, { waitUntil: `load` });
      const actual = await pagePuppet.title();
      const expected = `bitAdemy`;
      then(`it is ${expected}`, actual, expected);
    });
    await when(`we download all the content`, async () => {
      await pagePuppet.goto(inputPageUrl, { waitUntil: `networkidle2` });
      const content = await pagePuppet.content();
      const kiloByte = 1024;
      const maximumKiloBytes = 30;
      const maximunExpected = kiloByte * maximumKiloBytes;
      const actual = content.length < maximunExpected;
      const expected = true;
      then(`it is smaller than ${maximunExpected} bytes`, actual, expected);
    });
  });
};
```

En este caso comprobando t√≠tulo y tama√±o de la descarga. Ojo a las esperas. Porque en algunas situaciones nos basta esperar a la respuesta b√°sica del server y en otros necesitamos esperar a todo el contenido.

<div class="page"/>

# üé≠ Pruebas de aplicaciones web con Puppeteer

Puppeteer para emulaci√≥n, evaluaci√≥n del contenido y seguimiento de la prueba.

> _"Hacer las pruebas de existencia y rendimiento al terminar el desarrollo o tras las pruebas funcionales es como tomar el pulso o hacer una anal√≠tica a un paciente que ya est√° muerto."_
>
> -- ‚úçÔ∏è **Scott Barber**

Normalmente vas a querer comprobar algo m√°s que la existencia b√°sica de una web. Hay tantas posibles pruebas que hacer como situaciones pueda vivir un usuario. Pero para empezar te voy a mostrar las m√°s utilizadas.

### Emulaci√≥n

Algo t√≠pico es que despliegues una aplicaci√≥n web, pero quieras comprobar que se ejecuta correctamente en distintos dispositivos. Ya que Puppeteer usa por debajo un Chrome, podemos usar las capacidades de emulaci√≥n que tiene.

```javascript
module.exports = async function (pagePuppet) {
  await given(`Any page of my site`, async () => {
    const inputPageUrl = `https://www.bitademy.com`;
    const inputUserAgent =
      'Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1';
    await pagePuppet.setUserAgent(inputUserAgent);
    await pagePuppet.setViewport({ width: 375, height: 812 });
    await when(`we visit emulating an iPhone`, async () => {
      await pagePuppet.goto(inputPageUrl, { waitUntil: `load` });
      const actual = await pagePuppet.evaluate(() => {
        const nav = document.getElementById(`main-navigation`);
        const style = window.getComputedStyle(nav, ``);
        return style.getPropertyValue(`visibility`);
      });
      const expected = `hidden`;
      then(`it hides main-navigation`, actual, expected);
    });
  });
};
```
De esta forma puedes determinar si se aplican o no ciertos estilos, la validez de tus _media queries_...


### Evaluaci√≥n

Hablando de evaluar; te habr√°s fijado en la funci√≥n `evaluate` de primer orden que admite un _callback_ para ejecutar. La clave est√° en entender cu√°ndo esa funci√≥n se va a ejecutar. `Evaluate` ejecutar√° el _callback_ de forma as√≠ncrona una vez descargada la p√°gina.
Por ejemplo lo uso para comprobar que no tenemos links vac√≠os en una web.

```javascript
module.exports = async function (pagePuppet) {
  await given(`A site url`, async () => {
    const inputPageUrl = `https://www.bitademy.com`;
    await when(`we scrap it for empty links`, async () => {
      await pagePuppet.goto(inputPageUrl, { waitUntil: `load` });
      const actual = await pagePuppet.evaluate(() =>
        window.find(`a:is(:not([href]),[href=""],[href="#"])`)
      );
      const expected = false;
      then(`have no one`, actual, expected);
    });
  });
};
```

> Cualquier expresi√≥n JavaScript que pongamos se ejecutar√° como si la hubi√©ramos escrito en la consola del Chrome.

### Seguimiento

Adem√°s de lanzar el script y ver directo lo que ocurre, tambi√©n puedes querer ver lo que pas√≥ una vez terminado. Es decir comprobar qu√© ha ocurrido y tener un rastro; sobre todo si se ejecuta en modo desatendido o sin visualizaci√≥n.

```javascript
exports.takeScreenshot = async function takeScreenshot(pagePuppet) {
  const timeStamp = new Date().getTime();
  const shotPath = path.join(process.cwd(), 'images', `${timeStamp}.png`);
  await pagePuppet.screenshot({
    path: shotPath,
    fullPage: false
  });
};
```
La funci√≥n `screenshot` saca instant√°neas de las pantallas que permitir√°n analizar tranquilamente lo que ocurri√≥. Recuerda que la prueba la haces para ti. El _log_ o rastro de lo sucedido es tu principal activo al terminar la prueba.

<div class="page"/>

# üö¢ Pruebas de rendimiento web con Lighthouse

Lighthouse para comprobaci√≥n tama√±o, velocidad, SEO y otras m√©tricas.

> _"Cualquier optimizaci√≥n que no sea sobre el cuello de botella es una ilusi√≥n de mejora."_
>
> -- ‚úçÔ∏è **Federico Toledo**

Es decir, que antes de optimizar hay que medir y saber qu√© es lo que falla. Para medir de forma autom√°tica tras cada deploy, o cuando se establezca, te propongo que uses [Lighthouse](https://github.com/GoogleChrome/lighthouse).

Seguro que conoces _lighthouse_ como un complemento de _Chrome_. Pero aqu√≠ te voy a ense√±ar como integrarlo con _Puppeteer_ para realizar una pruebas de rendimiento. Pero vamos a **prepararlo y automatizarlo** de forma que sea muy sencillo y barato realizarlas con frecuencia.

Para seguir este tutorial no se requiere ning√∫n conocimiento previo sobre testing. Pero se recomienda familiarizarse con la terminolog√≠a leyendo el art√≠culo [Filosof√≠a y patrones](https://www.bitademy.com/tutorial/web-testing/filosofia-y-patrones)

## Lighthouse

Este producto de Google lo puedes usar de distintas formas manualmente. Para automatizarlo vamos a desarrollar un script Node que tome como dependencia a [su librer√≠a desde npm](https://www.npmjs.com/package/lighthouse)

Seguiremos las misma premisas que empleamos con [Puppeteer para las pruebas b√°sicas](tutorial/web-testing/e2e/pruebas-de-aplicaciones-web-con-puppeteer). Es decir la famosa _triple A_ **Arrange-Act-Assert**. Incluso con una √∫ltima _cuarta A_ **After** para organizar el c√≥digo. Y el _Given, when, then_ para informar al usuario del test, es decir al programador, copiado del _behavior-driven development._

### Arrange

Esta fase es un poco tediosa, pero te puede valer para todos los tests que hagas con _Lighthouse_. En esencia lanza una instancia de _Chrome_ y se conecta a ella. Es en esa instancia en la que se cargar√° tu p√°gina usando _Puppeteer_ y contra la que se lanzar√°n las peticiones de m√©tricas.

```javascript
async function arrangeBrowser() {
  const chrome = await launchChrome();
  console.info(`chrome.port : ${chrome.port}`);
  const browser = await connectToChrome(chrome);
  return { chrome, browser };
}

async function launchChrome() {
  const chrome = await chromeLauncher.launch(config);
  config.port = chrome.port;
  console.log(`Chrome launched at port: ${chrome.port}`);
  return chrome;
}
async function connectToChrome(chrome) {
  const resp = await util.promisify(request)(`http://localhost:${chrome.port}/json/version`);
  const { webSocketDebuggerUrl } = JSON.parse(resp.body);
  const browser = await puppeteer.connect({ browserWSEndpoint: webSocketDebuggerUrl });
  console.log(`Browser connected at url: ${browser._connection._url}`);
  return browser;
}
```

### Act

Esta fase es m√°s simple, aunque aqu√≠ si que tendr√°s que trabajar cada test. _Lighthouse_ es capaz de tomar cientos de m√©tricas y generar informes _json_ o _html_. Eso est√° muy bien, pero exige que algo o alguien los procese despu√©s.

Mi propuesta minimalista y enfocada al paso de la prueba es que pidas una m√©trica concreta y la valides contra un resultado esperado.

```javascript
module.exports = async function () {
  await given(`A deployed site`, async () => {
    const inputPageUrl = `https://www.bitademy.com`;
    const { chrome, browser, chrome_config } = await arrangeBrowser();
    await when(`we get the page audit scores`, async () => {
      const audits = await getAudits(inputPageUrl, chrome_config);
    });
  });
};
// Ver c√≥digo real en el laboratorio
exports.getAudits = async function getAudits(url, chrome_config) {
  lh_desktop_config.settings.skipAudits = null;
  lh_desktop_config.settings.onlyAudits = [
    'first-meaningful-paint',
    'speed-index',
    'first-cpu-idle',
    'interactive'
  ];
  const lh_audits = await lighthouse(url, chrome_config, lh_desktop_config).then(
    results => results.lhr.audits
  );
  return mapToSimpleArray(lh_audits);
};

```

Vale, pedir tan pocas m√©tricas quiz√° sea poco realista. Pero recuerda dos cosas antes de pedir a lo loco. **Las pruebas deben ser r√°pidas**. Y deben usarse con un objetivo concreto, **detectar y un cuello de botella y corregirlo**.

### Assert

Esta es la parte m√°s sencilla. Determina el umbral de rendimiento aceptable y comp√°ralo con el resultado obtenido. Por ejemplo yo aqu√≠ estoy midiendo el _speed-index_ , que es el criterio principal, y lo comparo contra el umbral que recomiendan en google.

```javascript
const minimumExpected = 0.89;
const expected = true;
const score = audits.find(a => a.id === 'speed-index').score;
const actual = score > minimumExpected;
then(`Speed Index faster than ${minimumExpected}`, actual, expected);
```

### After

Al acabar tus pruebas deber√≠as liberar los recursos, que3 en este caso es simplemente desconectar y cerrar la instancia de _chrome_

```javascript
browser.disconnect();
await chrome.kill();
```

> En [el laboratorio](https://github.com/LabsAdemy/WebTesting_e2e-puppeteer_Labs) tienes m√°s ejemplos de lo que es capaz _Lighthouse_. Y si a√∫n quieres m√°s puede mirar este otro repositorio a√∫n m√°s completo [AtomicBuilders/muon](https://github.com/AtomicBuilders/muon)

Con esto tienes para empezar en el mundo de las pruebas de las aplicaciones web, ojo que **empezamos por lo m√°s f√°cil de probar**. Pero algo salimos ganando, al menos comprobar que las p√°ginas respondan r√°pido. Ya veremos c√≥mo garantizar que adem√°s lo hagan correctamente.

<div class="page"/>

# üî≠ Pruebas de un API Rest

Pruebas de comunicaciones JSON

> _"Nunca hay pruebas suficientes que demuestren que un software est√° bien, pero un √∫nico test puede mostrar que est√° mal"_
>
> -- ‚úçÔ∏è **Amir Ghahrai**


Hemos visto que _Puppeteer_ es un automatizador de Chrome. Los navegadores solemos usarlo para ver p√°ginas web pero tambi√©n podemos, y como programadores debemos, usarlos para inspeccionar las comunicaciones de datos _json_. Con esto vas a poder probar tu API.

### Supertest

Para facilitar dichas inspecciones usaremos una librer√≠a con un nombre pretencioso: `supertest`. En esencia nos permite hacer peticiones _http_.

Veamos la llamada get m√°s sencilla posible. el _hello world_ de las API.

```javascript
async function getHello() {
  const inputHostUrl = `https://api-base.herokuapp.com`;
  await given(`the API url ${inputHostUrl}`, async () => {
    const inputEndPoint = `/api/pub/hello`;
    await when(`we call the ${inputEndPoint} endPoint`, async () => {
      const response = await request(inputHostUrl).get(inputEndPoint);
      const actual = response.body.message;
      const expected = `Hola Mundo`;
      then(`respond with the Hola Mundo message`, actual, expected);
    });
  });
}
```

### CRUD

Algo m√°s elaborado ser√≠a probar la comunicaci√≥n completa. Dejo la muestra de c√≥mo enviar una _payload_ con el m√©todo _post_

```javascript
async function postProject() {
  const inputHostUrl = `https://api-base.herokuapp.com`;
  await given(`the API url ${inputHostUrl}`, async () => {
    const inputEndPoint = `/api/pub/projects`;
    await when(`we post to the ${inputEndPoint} endPoint`, async () => {
      const inputProject = { name: 'start testing', dueDate: '2020-12-31' };
      const response = await request(inputHostUrl).post(inputEndPoint).send(inputProject);
      const actual = response.body.name;
      const expected = 'start testing';
      then(`respond with the same object`, actual, expected);
      const expectedStatus = 201;
      then(`respond with status code 201`, response.status, expectedStatus);
    });
  });
}
```

Como ves, se pueden comprobar respuestas, c√≥digos, cabeceras... Es decir, se trata de automatizar las llamadas al API y comprobar que las respuestas entran dentro de lo esperado. Todo ello sin frameworks especiales de pruebas, s√≥lo JavaScript con alguna librer√≠a de ayuda.

<div class="page"/>